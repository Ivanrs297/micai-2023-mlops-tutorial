{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Weights and Biases Tutorial for MICAI 2023\n",
        "*MLOps for Medical Image Made Easy*\n"
      ],
      "metadata": {
        "id": "OsHohHXGfxR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and Importing Dependencies"
      ],
      "metadata": {
        "id": "GayrdNCAf8lf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2QodINBfr53"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU\n",
        "\n",
        "import wandb\n",
        "import random\n",
        "import math\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "z7QsezIYf1Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running experiments\n",
        "\n",
        "- **Start a new run** and pass in hyperparameters to track\n",
        "- **Log metrics** from training or evaluation\n",
        "- **Visualize results** in the dashboard"
      ],
      "metadata": {
        "id": "3gQP3nIrgOH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_runs = 5\n",
        "for run in range(total_runs):\n",
        "  wandb.init(\n",
        "      project=\"intro-micai\",\n",
        "      name=f\"experiment_{run}\",\n",
        "\n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"learning_rate\": 0.02,\n",
        "      \"architecture\": \"CNN\",\n",
        "      \"dataset\": \"CIFAR-100\",\n",
        "      \"epochs\": 10,\n",
        "      })\n",
        "\n",
        "  # Simulates a training loop logging metrics\n",
        "  epochs = 10\n",
        "  offset = random.random() / 5\n",
        "\n",
        "  for epoch in range(2, epochs):\n",
        "      acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
        "      loss = 2 ** -epoch + random.random() / epoch + offset\n",
        "\n",
        "      wandb.log({\"acc\": acc, \"loss\": loss})\n",
        "\n",
        "  wandb.finish()"
      ],
      "metadata": {
        "id": "UNuFe_CqgQkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example with Simple Pytorch Neural Network for MNIST"
      ],
      "metadata": {
        "id": "FeFF9Orggn2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils Functions"
      ],
      "metadata": {
        "id": "xV10ZKitg9n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(is_train, batch_size, slice=5):\n",
        "    full_dataset = torchvision.datasets.MNIST(root=\".\", train=is_train, transform=T.ToTensor(), download=True)\n",
        "    sub_dataset = torch.utils.data.Subset(full_dataset, indices=range(0, len(full_dataset), slice))\n",
        "    loader = torch.utils.data.DataLoader(dataset=sub_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True if is_train else False,\n",
        "                                         pin_memory=True, num_workers=2)\n",
        "    return loader\n",
        "\n",
        "def get_model(dropout):\n",
        "    model = nn.Sequential(nn.Flatten(),\n",
        "                         nn.Linear(28*28, 256),\n",
        "                         nn.BatchNorm1d(256),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(dropout),\n",
        "                         nn.Linear(256,10)).to(device)\n",
        "    return model\n",
        "\n",
        "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
        "    model.eval()\n",
        "    val_loss = 0.\n",
        "    with torch.inference_mode():\n",
        "        correct = 0\n",
        "        for i, (images, labels) in enumerate(valid_dl):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if i==batch_idx and log_images:\n",
        "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
        "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n",
        "\n",
        "def log_image_table(images, predicted, labels, probs):\n",
        "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
        "\n",
        "    # Create a wandb Table to log predictions data\n",
        "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(10)])\n",
        "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
        "        table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
        "    wandb.log({\"predictions_table\":table}, commit=False)"
      ],
      "metadata": {
        "id": "3Gi7lkwWgkR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a model"
      ],
      "metadata": {
        "id": "RbpngiVqhQ0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Different dropout rates in 5 runs\n",
        "for _ in range(5):\n",
        "    wandb.init(\n",
        "        project=\"micai-pytorch-intro\",\n",
        "        config={\n",
        "            \"epochs\": 10,\n",
        "            \"batch_size\": 128,\n",
        "            \"lr\": 1e-3,\n",
        "            \"dropout\": random.uniform(0.01, 0.80),\n",
        "            })\n",
        "\n",
        "    config = wandb.config\n",
        "\n",
        "    train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)\n",
        "    valid_dl = get_dataloader(is_train=False, batch_size=2*config.batch_size)\n",
        "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
        "\n",
        "    model = get_model(config.dropout)\n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "    example_ct = 0\n",
        "    step_ct = 0\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        for step, (images, labels) in enumerate(train_dl):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            train_loss = loss_func(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct += len(images)\n",
        "            metrics = {\"train/train_loss\": train_loss,\n",
        "                       \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,\n",
        "                       \"train/example_ct\": example_ct}\n",
        "\n",
        "            if step + 1 < n_steps_per_epoch:\n",
        "                wandb.log(metrics)\n",
        "\n",
        "            step_ct += 1\n",
        "\n",
        "        val_loss, accuracy = validate_model(model, valid_dl, loss_func, log_images=(epoch==(config.epochs-1)))\n",
        "\n",
        "        val_metrics = {\"val/val_loss\": val_loss,\n",
        "                       \"val/val_accuracy\": accuracy}\n",
        "        wandb.log({**metrics, **val_metrics})\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    # example of test metrics\n",
        "    wandb.summary['test_accuracy'] = 0.8\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "GwSQhmq5hUbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra: Alerts\n",
        "\n",
        "```python\n",
        "wandb.alert(\n",
        "    title=\"Low accuracy\",\n",
        "    text=f\"Accuracy is below the acceptable threshold\"\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "IZgmYvZGhiBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Alerts"
      ],
      "metadata": {
        "id": "0Nvw9GY5hp4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"micai-pytorch-intro\")\n",
        "\n",
        "acc_threshold = 0.3\n",
        "for training_step in range(1000):\n",
        "\n",
        "    # Generate a random number for accuracy\n",
        "    accuracy = round(random.random() + random.random(), 3)\n",
        "    print(f'Accuracy is: {accuracy}, {acc_threshold}')\n",
        "\n",
        "    wandb.log({\"Accuracy\": accuracy})\n",
        "\n",
        "    # 🔔 If the accuracy is below the threshold, fire a W&B Alert and stop the run\n",
        "    if accuracy <= acc_threshold:\n",
        "        wandb.alert(\n",
        "            title='Low Accuracy',\n",
        "            text=f'Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}',\n",
        "        )\n",
        "        print('Alert triggered')\n",
        "        break\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "KCRQ6kERhoYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}